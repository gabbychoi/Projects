# AI 에이전트를 위한 API 거버넌스 가이드

---

## 🎯 문서 목적

- **대규모 언어 모델(LLM) 기반 에이전트**가 호출하는 API를 안전하고 일관되게 관리하기 위한 실무 지침 제공

- 대상 독자: 기획·PM, AI/ML 엔지니어, 백엔드·플랫폼 개발자, 보안·컴플라이언스 팀, DevOps/SRE

- 범위: API 카탈로그 → 접근 제어 → 런타임 가드레일 → 모니터링 & 비용 관리 → 지속적 평가

- 클라우드 환경으로 올수록 API 기반 개발은 이제 **필수적인 요소가 되어감.**  특히 AI Agent 는 API 호출을 수행하는 주체이기에 프롬프트에 따른 일관성 있는 응답을 보장하도록 설계할 필요가 있음.

> ℹ️ 본 문서는 세미나 인사이트·사내 논의를 **GPT로 구조화**하고, 인간 편집자가 사례·판단을 결합한 협업 산출물입니다.

---

## 1 | 왜 지금 거버넌스인가?

| 리스크 벡터         | 설명                                        | 통제 부재 시 영향     |
| -------------- | ----------------------------------------- | -------------- |
| **API 환각 호출**  | LLM이 **존재하지 않는** 엔드포인트/함수 생성·오타           | 워크플로 깨짐, 장애 증가 |
| **API 혼동 호출**  | 실제 존재하지만 **문맥을 잘못 이해**해 엉뚱한 엔드포인트·파라미터 호출 | 데이터 오염·업무 오류   |
| **잘못된 파라미터**   | 자유로운 프롬프트가 스키마 불일치 Payload 생성             | 데이터 오염·무음 실패   |
| **과도한 권한**     | 하나의 토큰으로 모든 쓰기/삭제 권한 보유                   | 보안 사고·규제 위반    |
| **API 스프롤·비용** | 중복·불필요 엔드포인트 급증                           | 유지비 상승, 복잡도 증가 |

> **용어 구분**
> 
> - **환각 호출 (Hallucinated Call)** : *존재하지 않는* API/함수를 모델이 창조하거나 오타로 호출
> 
> - **혼동 호출 (Confused Call)** : *존재하지만 엉뚱한* API·파라미터를 선택해 호출 두 오류는 원인·대응 방식이 달라 **별도 지표(환각률·혼동률)로 모니터링**한다.

> RPA(룰 기반 자동화)는 결정론적이라 이슈가 제한적이었지만, **확률적 추론 Agent**는 "휴먼에러형" 실수를 재현합니다.

---

## 2 | 거버넌스 계층 구조 (데이터 거버넌스 모델 차용)

```
도메인 (Domain)
 └─ API 컬렉션 (Collection)
     └─ 엔드포인트/오퍼레이션 (Endpoint)
         └─ 요청 및 응답 스키마 (Request/Response Schema)
```

| 레이어       | 정의 & 역할                        | LLM Agent 이점              |
| --------- | ------------------------------ | ------------------------- |
| **도메인**   | 하나의 비즈니스 영역 (HR, Sales 등)      | 프롬프트 단계에서 분야 필터링 가능       |
| **컬렉션**   | 도메인 내 기능별 묶음 (HR‑Scheduling 등) | 유사 기능 중복·혼동 방지, 권한도 묶음 관리 |
| **엔드포인트** | 실제 호출 URI + 메서드                | 호출 가능 목록 축소 → 환각·오타 감소    |
| **스키마**   | JSON Schema/OpenAPI            | 요청·응답 검증, 자동 수정 가능        |

### 적용 팁

1. 위 계층을 **JSON/YAML 카탈로그**로 만들어 `tools` 파라미터에 주입

2. 권한·RateLimit을 *도메인/컬렉션* 단위로 관리해 운영 부담 최소화

3. 모니터링 대시보드도 동일 트리 구조로 드릴다운 구성

4. 신규 API PR 시 **도메인·컬렉션 매핑 필드**를 템플릿에 강제

---

## 3 | 거버넌스 5대 기둥

| 기둥             | 필수 통제                                     | 권장 확장                              |
| -------------- | ----------------------------------------- | ---------------------------------- |
| **카탈로그 & 탐색성** | 중앙 API 레지스트리(OpenAPI/JSON Schema) · 버전 정책 | 도메인·리스크 태깅 · 자동 스키마 린트             |
| **접근 제어**      | 에이전트별 Role‑based 토큰 · 읽기/쓰기 분리            | JIT 토큰 · 비밀키 회전 파이프라인              |
| **런타임 가드레일**   | 스키마 검증 미들웨어 · Rate/Quota 제한               | 정책 코드(OPA)로 승인되지 않은 호출 거절          |
| **모니터링 & 비용**  | 호출·지연·오류 로그 · 비용 계측                       | "환각률"(Invalid/Total) 지표 · 이상 탐지 알람 |
| **지속적 평가**     | A/B 또는 섀도 테스트 · 월간 감사 리포트                 | 프롬프트 피드백 루프(Self‑Healing)          |

---

### 3.1 | API Governance Engineer 역할 상세

| 역할                          | 주요 태스크                                                                                                                                                                                                        |
| --------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **API Governance Engineer** | · 도메인→컬렉션→엔드포인트 메타데이터 수집·정합성 유지 권한 · RateLimit·스키마 검증 로직(OPA/TypeScript) 구현 · 환각·혼동 지표 대시보드 운영, 이상 탐지  Incident Response 연동 · API 호출·토큰 비용을 모델·에이전트·도메인 단위로 리포트· 신규 API·Agent 배포 시 GitOps 릴리즈 게이트·승인 파이프라인 운영 |

> 🔍 **배경** : 기존 ‘풀스택 엔지니어’만으로는 LLM + 다중 API 시대의 정책·보안·비용·품질 을 동시에 관리하기 어려워졌기 때문에 전담 역할이 필요합니다.

### 3.2 | 3‑2 프로젝트 인력 구성 | 3‑2 프로젝트 인력 구성

| 역할                                    | 주요 태스크                                                         |
| ------------------------------------- | -------------------------------------------------------------- |
| **API Governance Engineer & Planner** | · API 카탈로그/정책 설계· 거버넌스 로드맵·ROI 플래닝· 릴리즈 게이트·승인 프로세스 운영         |
| **ML Engineer & Prompt Engineer**     | · 모델 선택·파인튜닝·실험 관리· 프롬프트 디자인·AB 테스트·평가 지표 설계                   |
| **DPA & RAG Flow Engineer**           | · 데이터 사전처리(DPA)·PII 마스킹· 벡터 인덱스 구축·RAG 파이프라인 오케스트레이션           |
| **Data Engineer & DBA**               | · 원천 DB‑ETL·데이터 품질 모니터링· 스키마 버전·백업·성능 튜닝                       |
| **Infra Engineer (DevOps/SRE)**       | · Azure 리소스 그룹·VNet·CI/CD· 모니터링(환각·혼동 지표 수집)·오토스케일·Incident 대응 |

> 이 5개 역할 스쿼드로 AoAI 환경 기준 **PoC → 프로덕션** 전 과정을 소화할 수 있다. (단, UX 프론트 통합은 추가 인력이 필요할 수 있음)

$2 | 2주 PoC 제안사항

1. **범위 선정**: 에이전트 1개 혼동가능성 있는 플로우 집합 2-3개 작성(혼동가능한 플로우 2개를 묶어 플로우 집합 구성 총 4-6 개의 플로우 테스트)

2. **계측**: 스키마·Auth 미들웨어 적용, 모든 호출 로깅

3. **지표 목표
   
   - 성공률 ≥ 70 %
   
   - **환각률 ≤ 2 %**
   
   - **혼동률 ≤ 5 %**

4. **리뷰 & 확대**: 목표 달성 시 스코프 확장, 미달 시 프롬프트·권한·스키마 개선

---

## 5 | 구현·A/B 체크리스트

| 단계        | 사람용 거버넌스(Ops)                       | AI‑사용 가능 지침 파일(Policy)                                            | 검증 방법               |
| --------- | ----------------------------------- | ----------------------------------------------------------------- | ------------------- |
| ① 설계      | · 도메인→컬렉션→엔드포인트 문서화· 승인·버전·권한 절차 명시 | · `catalog.json` : 계층 메타데이터· 각 엔드포인트 `openapi.yaml`·`schema.json` | 문서 리뷰 & 스키마 린트      |
| ② 배포      | 내부 위키/Notion 등록, PR 템플릿에 매핑 필드 강제   | 런타임 미들웨어에 카탈로그 주입(`tools`)                                        | CI/CD 에서 스키마 불일치 체크 |
| ③ A/B 테스트 | 컨트롤(A) : 정책 미적용 인스턴스                | 테스트(B) : 정책 적용 인스턴스                                               | 2주간 호출 로그·비용 수집     |
| ④ 지표      | 성공률·장애율·MTTR                        | 환각률(환각 호출/Total) · 혼동률(혼동 호출/Total)·비용                            | 통계 검정(p<0.05)       |
| ⑤ 승격      | 문서 갱신·정책 의무화                        | 미들웨어 기본 온(Default‑ON)                                             | 결과 리포트 공유           |

> **TIP** 컨트롤 그룹은 최소화(트래픽 10 %)해 비용을 절감하고, B그룹의 개선폭이 10 % 이상이면 조직 표준화한다.

---

## 6 | 참고 사고·사례

| 출처                                    | 핵심 교훈                                              | 관련 링크                                                                                                                                                                                                                                                                                                 |     |
| ------------------------------------- | -------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --- |
| **OpenAI Function Calling 데모 (2023)** | LLM이 *정의되지 않은 함수*를 ‘환각’ 호출 → 런타임 장애                | [How to stop model from hallucinating function names? - API - OpenAI Developer Community](https://community.openai.com/t/how-to-stop-model-from-hallucinating-function-names/591674)                                                                                                                  |     |
| **다(多)-Tool Agent 커뮤니티 사례 (2024)**    | 10개 이상 툴 등록 환경에서 *미지원 툴* 3회 연속 호출 → 무한 루프·토큰/비용 폭증 | [GPT-4-0125-preview hallucinating tool calls - API - OpenAI Developer Community](https://community.openai.com/t/gpt-4-0125-preview-hallucinating-tool-calls/609610)                                                                                                                                   |     |
| **AWS Bedrock PoC (2024)**            | 질문–응답 캐시·검증 레이어로 환각 차단 → **API 비용 35 %↓**          | [Reducing hallucinations in LLM agents with a verified semantic cache using Amazon Bedrock Knowledge Bases \| AWS Machine Learning Blog](https://aws.amazon.com/ko/blogs/machine-learning/reducing-hallucinations-in-llm-agents-with-a-verified-semantic-cache-using-amazon-bedrock-knowledge-bases/) |     |

## 7 | 우리 조직의 다음 스텝

1. Data Portal 혹은 현재 구성중인 AI Agent 에 적용

2. 검증된 통제 방안을 수립 및 **조직 표준 정책**으로 승격

*문서 버전 0.3 — 업데이트 2025‑04‑25* | 참고 사고·사례
